
# ChatPDF with Amazon Bedrock & FAISS

Interact with your PDF files using natural language! This Streamlit-powered application leverages Amazon Bedrock's large language models (Claude v2 and LLaMA3-70B) for intelligent question answering and FAISS for document retrieval.

## ğŸš€ Features

- ğŸ“„ Upload and process PDFs automatically from the `data/` directory.
- ğŸ” Chunk and embed text using `amazon.titan-embed-text-v1` from Bedrock.
- ğŸ§  Retrieve answers using:
  - ğŸ§‘â€ğŸ« **Claude v2** (Anthropic)
  - ğŸ¦™ **LLaMA 3 70B Instruct** (Meta)
- ğŸ§  Vector indexing and similarity search powered by **FAISS**.
- ğŸŒ Fully interactive **Streamlit** UI.

---

## ğŸ› ï¸ Tech Stack

- **Frontend/UI:** Streamlit
- **Embedding & LLMs:** Amazon Bedrock (Titan Embedding, Claude, LLaMA3)
- **Vector DB:** FAISS
- **PDF Processing:** LangChain `PyPDFDirectoryLoader`
- **Text Splitting:** RecursiveCharacterTextSplitter

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ app.py                 # Main application logic
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ data/                  # PDF files directory
â”œâ”€â”€ faiss_index/           # Stores FAISS vector index files
â”‚   â”œâ”€â”€ index.faiss
â”‚   â””â”€â”€ index.pkl
â”œâ”€â”€ venv/                  # (Optional) Virtual environment
```

---

## ğŸ“¥ Installation

1. **Clone the Repository**

```bash
git clone https://github.com/jayd972/ChatPDF-with-Amazon-Bedrock-FAISS-Ask-Questions-from-PDFs-using-Claude-or-LLaMA2.git
cd ChatPDF-with-Amazon-Bedrock-FAISS-Ask-Questions-from-PDFs-using-Claude-or-LLaMA2
```

2. **Create a Virtual Environment**

```bash
python -m venv venv
source venv/bin/activate  # or .\venv\Scripts\activate on Windows
```

3. **Install Requirements**

```bash
pip install -r requirements.txt
```

4. **Configure AWS Bedrock**

Ensure your AWS credentials are configured to access Bedrock services:

```bash
aws configure
```

Youâ€™ll need access to the following Bedrock models:
- `amazon.titan-embed-text-v1`
- `anthropic.claude-v2`
- `meta.llama3-70b-instruct-v1:0`

---

## ğŸ§ª Run the App

```bash
streamlit run app.py
```

---

## ğŸ“ Usage

1. Place your PDF files inside the `/data` directory.
2. Launch the app.
3. Click **â€œVectors Updateâ€** in the sidebar to create a new FAISS index.
4. Type your question.
5. Click on **â€œClaude Outputâ€** or **â€œLlama2 Outputâ€** to get an answer based on your vector store.

---

## ğŸ“Œ Notes

- Adjust chunk sizes in `RecursiveCharacterTextSplitter` if you're working with large or complex documents.
- The default embedding model is `amazon.titan-embed-text-v1`; you can swap this as needed.

---

## ğŸ¤ Contributing

Feel free to fork the repository and submit pull requests for enhancements or fixes. Contributions are always welcome!
